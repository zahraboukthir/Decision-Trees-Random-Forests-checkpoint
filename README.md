# Decision-Trees-Random-Forests-checkpoint
Objective
Decision Trees & Random Forests
We are going to predict once again if a passenger on the Titanic is going to survive. This time  using decision trees and random forests: 

1. Read your Titanic dataset as usual: Create a training set and a testing set then apply decision tree. 

2. Plot your decision tree and try to read the tree branches and conclude a prediction manually.

3. Change the decision tree parameters(at least two parameters). 

4. Calculate the new accuracy and compare it with the previous results. 

5. Use a random forest then change the number of estimators.

6. Calculate the new accuracy and compare it with the previous result.
 
